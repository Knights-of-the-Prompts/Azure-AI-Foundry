import os
import time
from pathlib import Path
from urllib.parse import urlparse, parse_qs

from azure.ai.projects import AIProjectClient
from azure.ai.agents.models import ThreadMessage
from azure.storage.blob import BlobServiceClient, ContainerClient

from terminal_colors import TerminalColors as tc


class Utilities:
    def log_msg_green(self, msg: str) -> None:
        """Print a message in green."""
        print(f"{tc.GREEN}{msg}{tc.RESET}")

    def log_msg_purple(self, msg: str) -> None:
        """Print a message in purple."""
        print(f"{tc.PURPLE}{msg}{tc.RESET}")

    def log_token_blue(self, msg: str) -> None:
        """Print a token in blue."""
        print(f"{tc.BLUE}{msg}{tc.RESET}", end="", flush=True)

    def get_file(self, project_client: AIProjectClient, file_id: str, attachment_name: str) -> None:
        """Retrieve the file and save it to the local disk."""
        self.log_msg_green(f"Getting file with ID: {file_id}")

        file_name, file_extension = os.path.splitext(
            os.path.basename(attachment_name.split(":")[-1]))
        file_name = f"{file_name}.{file_id}{file_extension}"

        env = os.getenv("ENVIRONMENT", "local")
        folder_path = Path(f"{'src/workshop/' if env == 'container' else ''}files")

        folder_path.mkdir(parents=True, exist_ok=True)

        file_path = folder_path / file_name

        # Save the file using a synchronous context manager
        with file_path.open("wb") as file:
            for chunk in project_client.agents.get_file_content(file_id):
                file.write(chunk)

        self.log_msg_green(f"File saved to {file_path}")
        # Cleanup the remote file
        project_client.agents.delete_file(file_id)

    def get_files(self, message: ThreadMessage, project_client: AIProjectClient) -> None:
        """Get the image files from the message and kickoff download."""
        if message.image_contents:
            for index, image in enumerate(message.image_contents, start=0):
                attachment_name = (
                    "unknown" if not message.file_path_annotations else message.file_path_annotations[
                        index].text
                )
                self.get_file(project_client, image.image_file.file_id, attachment_name)
        elif message.attachments:
            for index, attachment in enumerate(message.attachments, start=0):
                attachment_name = (
                    "unknown" if not message.file_path_annotations else message.file_path_annotations[
                        index].text
                )
                self.get_file(project_client, attachment.file_id, attachment_name)

    def download_agent_files(self, project_client: AIProjectClient, thread_id: str, downloads_dir: str = None) -> None:
        """Download all files generated by the agent (code interpreter, etc.)."""
        try:
            messages = project_client.agents.messages.list(thread_id=thread_id)
            
            # Create downloads directory if it doesn't exist
            import os
            if downloads_dir is None:
                env = os.getenv("ENVIRONMENT", "local")
                downloads_dir = f"{'src/workshop/' if env == 'container' else ''}files"
            
            if not os.path.exists(downloads_dir):
                os.makedirs(downloads_dir)
            
            # Get the latest agent message only (to avoid redownloading old files)
            latest_agent_message = None
            for message in messages:
                if message.role.value == "assistant":
                    latest_agent_message = message
                    break
            
            if not latest_agent_message:
                return  # No agent messages to process
            
            # Track downloaded file IDs to avoid duplicates
            downloaded_file_ids = set()
            
            # First, process file path annotations (primary method for code interpreter files)
            if hasattr(latest_agent_message, 'file_path_annotations') and latest_agent_message.file_path_annotations:
                for file_path_annotation in latest_agent_message.file_path_annotations:
                    file_id = file_path_annotation.file_path.file_id
                    
                    if file_id in downloaded_file_ids:
                        continue  # Skip if already downloaded
                    
                    # Get original filename from the annotation text if possible
                    annotation_text = file_path_annotation.text
                    if "/" in annotation_text:
                        original_filename = annotation_text.split("/")[-1]
                    else:
                        original_filename = f"{file_id}_annotation_file"
                    
                    local_path = os.path.join(downloads_dir, original_filename)
                    
                    try:
                        # Download file content from Azure AI
                        file_content_generator = project_client.agents.files.get_content(file_id=file_id)
                        file_content = b''.join(file_content_generator)
                        with open(local_path, "wb") as f:
                            f.write(file_content)
                        self.log_msg_green(f"Downloaded generated file: {local_path}")
                        downloaded_file_ids.add(file_id)
                    except Exception as e:
                        print(f"Error downloading file {file_id}: {e}")
            
            # Second, check content items for any files not caught by annotations
            if hasattr(latest_agent_message, 'content') and latest_agent_message.content:
                for content_item in latest_agent_message.content:
                    file_id = None
                    file_name = None
                    
                    # Check for different types of content
                    if hasattr(content_item, 'type'):
                        # Handle image_file type
                        if content_item.type == 'image_file' and hasattr(content_item, 'image_file'):
                            file_id = content_item.image_file.file_id
                            file_name = f"{file_id}_image.png"
                        
                        # Handle file_path type (for other files)
                        elif content_item.type == 'file_path' and hasattr(content_item, 'file_path'):
                            file_id = content_item.file_path.file_id
                            file_name = f"{file_id}_file"
                    
                    # Skip if no file found or already downloaded
                    if not file_id or file_id in downloaded_file_ids:
                        continue
                    
                    local_path = os.path.join(downloads_dir, file_name)
                    
                    try:
                        # Download file content from Azure AI
                        file_content_generator = project_client.agents.files.get_content(file_id=file_id)
                        file_content = b''.join(file_content_generator)
                        with open(local_path, "wb") as f:
                            f.write(file_content)
                        self.log_msg_green(f"Downloaded file: {local_path}")
                        downloaded_file_ids.add(file_id)
                    except Exception as e:
                        print(f"Error downloading file {file_id}: {e}")
            
        except Exception as e:
            print(f"Error handling file downloads: {e}")

    def search_local_files(self, directory: Path, search_term: str) -> list[Path]:
        """Search for files in the local directory using a search term."""
        self.log_msg_purple(f"Searching in {directory} for: {search_term}")
        
        try:
            # Convert search term to lowercase for case-insensitive search
            search_term = search_term.lower()
            results = []
            
            # Make sure directory exists
            if not directory.exists():
                self.log_msg_purple(f"Directory {directory} does not exist")
                return results
                
            # Search through all PDF files in the directory
            for file_path in directory.glob("**/*.pdf"):
                try:
                    # Check filename first
                    if search_term in file_path.name.lower():
                        results.append(file_path)
                        continue
                        
                    # If not found in filename, check content
                    from pdfminer.high_level import extract_text
                    content = extract_text(str(file_path)).lower()
                    
                    if search_term in content:
                        results.append(file_path)
                        self.log_msg_green(f"Found match in: {file_path.name}")
                        
                except Exception as file_error:
                    self.log_msg_purple(f"Error processing file {file_path}: {str(file_error)}")
                    continue
            
            self.log_msg_green(f"Found {len(results)} matching files")
            return results
            
        except Exception as e:
            self.log_msg_purple(f"Error during search: {str(e)}")
            return []

    def download_from_blob_storage(self, storage_account_name: str, storage_key: str, container_name: str, target_dir: Path) -> list[Path]:
        """Download new or updated files from Azure Blob Storage using storage account credentials."""
        self.log_msg_purple(f"=== Starting Azure Blob Storage Synchronization ===")
        
        # Validate inputs
        if not storage_account_name or not storage_account_name.strip():
            raise ValueError("Storage account name cannot be empty")
        if not storage_key or not storage_key.strip():
            raise ValueError("Storage account key cannot be empty")
        if not container_name or not container_name.strip():
            raise ValueError("Container name cannot be empty")
            
        # Log configuration (mask storage key for security)
        self.log_msg_purple(f"Storage Account: {storage_account_name}")
        self.log_msg_purple(f"Container: {container_name}")
        self.log_msg_purple(f"Target Directory: {target_dir}")
        self.log_msg_purple(f"Key Length: {len(storage_key)} characters")
        downloaded_files = []
        
        try:
            # Construct the account URL
            account_url = f"https://{storage_account_name}.blob.core.windows.net"
            self.log_msg_purple(f"Establishing connection to Azure Storage account...")
            self.log_msg_purple(f"Account URL: {account_url}")
            
            # Validate storage key format (basic check)
            if len(storage_key) < 64 or '==' not in storage_key:
                self.log_msg_purple("âš ï¸  Warning: Storage key format might be invalid")
                self.log_msg_purple("    Expected format: Base64 encoded key ending with '=='")
            
            try:
                # Create the blob service client using account key
                self.log_msg_purple("Initializing Blob Service Client...")
                blob_service_client = BlobServiceClient(
                    account_url=account_url,
                    credential=storage_key
                )
                
                # Test connection with a simple operation
                self.log_msg_purple("Testing connection...")
                account_info = blob_service_client.get_account_information()
                self.log_msg_green("âœ“ Successfully connected to Azure Storage account")
                self.log_msg_purple(f"Account SKU: {account_info['sku_name']}")
                
            except Exception as auth_error:
                error_message = str(auth_error)
                if "AuthorizationFailure" in error_message:
                    self.log_msg_purple("âŒ Authorization Failed. Common causes:")
                    self.log_msg_purple("   1. Invalid storage account key")
                    self.log_msg_purple("   2. Key does not have sufficient permissions")
                    self.log_msg_purple("   3. Account name and key mismatch")
                raise Exception(f"Authentication failed: {error_message}")
            
            self.log_msg_purple(f"Accessing container '{container_name}'...")
            container_client = blob_service_client.get_container_client(container_name)
            self.log_msg_green("âœ“ Successfully connected to container")
            
            # Ensure target directory exists
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # Get list of existing local files and their sizes
            self.log_msg_purple("Scanning local directory for existing files...")
            local_files = {}
            total_local_size = 0
            for file_path in target_dir.glob('*'):
                if file_path.is_file():
                    file_size = file_path.stat().st_size
                    local_files[file_path.name] = file_size
                    total_local_size += file_size
            
            self.log_msg_purple(f"Found {len(local_files)} existing local files")
            self.log_msg_purple(f"Total local storage used: {total_local_size / (1024*1024):.2f} MB")
            
            # List all blobs in the container
            self.log_msg_purple("Retrieving blob list from Azure Storage...")
            blob_list = list(container_client.list_blobs())
            total_blob_size = sum(blob.size for blob in blob_list)
            self.log_msg_purple(f"Found {len(blob_list)} files in blob storage")
            self.log_msg_purple(f"Total blob storage size: {total_blob_size / (1024*1024):.2f} MB")
            
            # Compare and download only new or updated files
            for blob in blob_list:
                try:
                    target_path = target_dir / blob.name
                    should_download = False
                    
                    # Check file status
                    if blob.name not in local_files:
                        self.log_msg_purple(f"ðŸ“„ New file detected: {blob.name}")
                        self.log_msg_purple(f"   Size: {blob.size / 1024:.2f} KB")
                        should_download = True
                    elif local_files[blob.name] != blob.size:
                        self.log_msg_purple(f"ðŸ”„ File update detected: {blob.name}")
                        self.log_msg_purple(f"   Current size: {local_files[blob.name] / 1024:.2f} KB")
                        self.log_msg_purple(f"   New size: {blob.size / 1024:.2f} KB")
                        should_download = True
                    
                    if should_download:
                        self.log_msg_purple(f"â¬‡ï¸  Downloading: {blob.name}")
                        self.log_msg_purple(f"   Destination: {target_path}")
                        self.log_msg_purple(f"   Size: {blob.size / 1024:.2f} KB")
                        
                        # Track download progress
                        start_time = time.time()
                        blob_client = container_client.get_blob_client(blob.name)
                        
                        with open(target_path, "wb") as file:
                            data = blob_client.download_blob()
                            file.write(data.readall())
                            
                        end_time = time.time()
                        duration = end_time - start_time
                        speed = (blob.size / 1024 / 1024) / duration  # MB/s
                        
                        downloaded_files.append(target_path)
                        self.log_msg_green(f"âœ… Successfully downloaded: {target_path}")
                        self.log_msg_green(f"   Duration: {duration:.2f} seconds")
                        self.log_msg_green(f"   Speed: {speed:.2f} MB/s")
                    else:
                        self.log_msg_purple(f"â­ï¸  Skipping unchanged file: {blob.name}")
                        self.log_msg_purple(f"   Size: {blob.size / 1024:.2f} KB")
                    
                except Exception as blob_error:
                    self.log_msg_purple(f"Error processing blob {blob.name}: {str(blob_error)}")
                    continue
            
            self.log_msg_green(f"Downloaded {len(downloaded_files)} new or updated files")
            return downloaded_files
            
        except Exception as e:
            self.log_msg_purple(f"Error accessing blob storage: {str(e)}")
            return downloaded_files
            
    def sync_vector_store_files(self, project_client: AIProjectClient, vector_store_id: str, target_dir: Path) -> list[Path]:
        """Download and sync all files from a vector store to a local directory."""
        self.log_msg_purple(f"Starting sync for vector store: {vector_store_id}")
        self.log_msg_purple(f"Target directory: {target_dir.absolute()}")
        
        downloaded_files = []
        
        try:
            # Ensure target directory exists
            target_dir.mkdir(parents=True, exist_ok=True)
            self.log_msg_purple("Target directory created/verified")
            
            # Get vector store details
            self.log_msg_purple("Fetching vector store details...")
            vector_store = project_client.agents.get_vector_store(vector_store_id)
            self.log_msg_green(f"Found vector store with {len(vector_store.file_ids)} files")
            
            # Process each file
            for file_id in vector_store.file_ids:
                try:
                    self.log_msg_purple(f"Processing file ID: {file_id}")
                    
                    # Get file metadata using agents API
                    file_info = project_client.agents.get_file(file_id)
                    target_path = target_dir / f"{file_info.filename}"
                    
                    self.log_msg_purple(f"Downloading to: {target_path.absolute()}")
                    
                    # Download file content
                    with target_path.open("wb") as f:
                        for chunk in project_client.agents.download_file(file_id):
                            f.write(chunk)
                    
                    downloaded_files.append(target_path)
                    self.log_msg_green(f"Successfully downloaded: {target_path.name}")
                    
                except Exception as file_error:
                    self.log_msg_purple(f"Error downloading file {file_id}: {str(file_error)}")
                    continue
                    
            return downloaded_files
            
        except Exception as e:
            self.log_msg_purple(f"Error in vector store sync: {str(e)}")
            return downloaded_files
        for file_id in vector_store.file_ids:
            try:
                # Get file metadata
                file_info = project_client.files.get(file_id)
                target_path = target_dir / f"{file_info.filename}"
                
                self.log_msg_purple(f"Downloading: {file_info.filename}")
                
                # Download and write file
                with target_path.open("wb") as f:
                    for chunk in project_client.files.download(file_id):
                        f.write(chunk)
                        
                downloaded_files.append(target_path)
                self.log_msg_green(f"Successfully downloaded: {target_path}")
                
            except Exception as e:
                self.log_msg_purple(f"Error downloading file {file_id}: {e}")
                continue
                
        return downloaded_files
